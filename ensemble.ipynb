{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"r\n",
    "Created on Tue Jul 25 2017\n",
    "\n",
    "@author: Nicolas Loffreda\n",
    "\n",
    "Module to read all the images located on a particular folder, convert them to\n",
    "an np array, flatten them and put them together on an np Array format to use as\n",
    "Data Matrix (Feature Vector)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pylab as pl\n",
    "\n",
    "def readImages(path, chk_shape=(50, 50)):\n",
    "    '''\n",
    "    Read all images from a directory and return an np Array X to use\n",
    "    as data matrix (Feature Vectors).\n",
    "    The function will also check for a specific shape and raise an error if \n",
    "    dimensions don't match what's expected (usually 50x50, but can be changed)\n",
    "    \n",
    "    Parameters & Return\n",
    "    ----------\n",
    "    :param path: Path where the images are located\n",
    "    :param chk_shape: Tuple (1x2) to check image shape\n",
    "    :return X: Data matrix with each image on a flattened format\n",
    "    \n",
    "    Example\n",
    "    -----------\n",
    "    :Example:\n",
    "        \n",
    "    >> X = readImages(\"./imgs\", chk_shape=(145,148))\n",
    "    >> X = readImages(\"./imgs\")\n",
    "    '''\n",
    "    # Read Images\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    for img in os.listdir(path):\n",
    "        if img.endswith(\".png\") or img.endswith(\".jpg\"):\n",
    "            im = Image.open(os.path.join(path, img))\n",
    "            im_grey = im.convert('L')\n",
    "            im_array = np.array(im_grey)\n",
    "            if im_array.shape != chk_shape:\n",
    "                raise ValueError('{} doesnt have the expected dim {}, {} instead'.format(img, chk_shape, im_array.shape))\n",
    "            images.append(im_array)\n",
    "            # obtain class value\n",
    "            class_id = int(img.split('_')[0].lstrip('c'))\n",
    "            labels.append(class_id)\n",
    "            \n",
    "    # Flatten the images and append to Data matrix\n",
    "    flatimages = list()\n",
    "    for i in images:\n",
    "        flatimages.append(i.ravel())\n",
    "    X = np.asarray(flatimages)\n",
    "    y = np.asarray(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Vicky\\Documents\\berkeley_ext_course\\intro_to_ML_using_python\\final_project_test\\all_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import image data and labels\n",
    "X, y = readImages(path, chk_shape=(50, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and training data\n",
    "def train_test_split(X, y, test_size=None, random_state=None):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    -X: data, with shape (N, d)\n",
    "    -y: label, with shape (N, )\n",
    "    -test_size: float. 0-1\n",
    "    -random_state: define randome state, for reproducing same random sequence. int   \n",
    "    \"\"\"\n",
    "    if random_state == None:\n",
    "        random_state = 42\n",
    "    if test_size == None:\n",
    "        test_size = 0.25\n",
    "        \n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    \n",
    "    test_size = int(len(X)*test_size)\n",
    "    test_ind = indices[:test_size]\n",
    "    train_ind = indices[test_size:]\n",
    "    \n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_test, y_test = X[test_ind], y[test_ind]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# count the number of each class in the training set\n",
    "from collections import Counter\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Nicolas Loffreda\n",
    "@date: 6/24/2017\n",
    "\n",
    "Code to apply Principal Component Analysis (PCA) to a feature matrix\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def applyPCA(X, components=2, return_code='P'):\n",
    "    '''\n",
    "    Calculate the PCA of a feature matrix.\n",
    "    Can be controled to set the number of PCA components we want to use.\n",
    "    Will return P Matrix with dimension N x components\n",
    "    '''\n",
    "    if type(X) != np.ndarray:\n",
    "        raise TypeError('Type of X must be a numpy array')\n",
    "    if components > X.shape[1]:\n",
    "        raise ValueError(\"Number of components can't be more than the number of features: \" + str(X.shape[1]))\n",
    "        \n",
    "    # Normalize Feature Vector: Z\n",
    "    mean_vec = X.mean(axis=0)\n",
    "    Z = X - mean_vec\n",
    "\n",
    "    # Covariance Matrix: C\n",
    "    C = np.cov(X, rowvar=False)\n",
    "    \n",
    "    # EigenVectors: V\n",
    "    eigvals, V = np.linalg.eigh(C)\n",
    "    eigvals=np.flipud(eigvals)\n",
    "    V=np.flipud(V.T)\n",
    "    V = V[:components]\n",
    "    \n",
    "    # Principal Components matrix: P\n",
    "    P = np.dot(Z,V.T)\n",
    "    \n",
    "    # Recuperated Matrix: X_Rec\n",
    "    X_rec = np.dot(P, V) + mean_vec\n",
    "    \n",
    "    if return_code == 'P':\n",
    "        return P\n",
    "    if return_code == 'PX':\n",
    "        return P, X_rec\n",
    "    elif return_code == 'all':\n",
    "        return mean_vec, Z, C, P, V, X_rec, eigvals\n",
    "    else:\n",
    "        raise ValueError('Invalid return code: P, PX, all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "mean_vec, _, _, P, V, _, eigvals = applyPCA(X_train, components=2, return_code='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ids = [0,1,2,3,4,5]\n",
    "colors = ['cyan', 'red', 'green', 'orange', 'blue', 'magenta']\n",
    "# plot first 2 principle components\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['left'].set_color('gray')\n",
    "for i in np.arange(len(class_ids)):\n",
    "    plt.scatter(P[:,0][y_train==class_ids[i]], P[:,1][y_train==class_ids[i]], c=colors[i], s = 10, label = \"class %i\"%class_ids[i], alpha=0.7)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_linear_classifier:\n",
    "    \"\"\"\n",
    "    Implementation of ensemble linear classifiers algorithm. None linear transformation using Tanh.\n",
    "\n",
    "    Input:\n",
    "    -X: training data, with shape (N, d)\n",
    "    -query: query data, with shape (N, d)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, n_estimators=30, random_state=42):\n",
    "        \"\"\"r\n",
    "        n_estimators: number of linear classifier\n",
    "        random_state: for generating random seeding\n",
    "        Keslerlabel: dictionary to show corresponding class value in Kesler construction\n",
    "        w: weight\n",
    "        e: error weight for ensembled classifier\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.random_state = random_state\n",
    "        self.Keslerlabel = None\n",
    "        self.w = None\n",
    "        self.e = None\n",
    "\n",
    "    def _Kesler_construction(self, X, y):\n",
    "        # convert y to Kesler constructions, positive class +1, negative class -1\n",
    "        class_values = np.unique(y)\n",
    "        class_num = len(class_values)\n",
    "        yc = np.zeros_like(y)\n",
    "\n",
    "        for i, value in enumerate(class_values):\n",
    "            yc[y==value]=i\n",
    "\n",
    "        KC = np.zeros((len(X), class_num))\n",
    "        KC.fill(-1)\n",
    "        KC[range(len(X)), yc]=1\n",
    "\n",
    "        self.Keslerlabel = {ind:value for ind, value in enumerate(class_values)}\n",
    "\n",
    "        return KC\n",
    "\n",
    "    def _Xa_construction(self, X):\n",
    "        # add x0=1\n",
    "        Xa = np.hstack((np.ones((len(X),1)), X))\n",
    "        return Xa\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # construct weight\n",
    "        M = self.n_estimators\n",
    "        N, d = X.shape\n",
    "\n",
    "        # generate random weights and normalize\n",
    "        np.random.seed(self.random_state)\n",
    "        w = np.random.uniform(-1,1,(M,d))\n",
    "        w = w/np.linalg.norm(w, axis=1, keepdims=True)\n",
    "\n",
    "        # random select M samples from X\n",
    "        np.random.seed(self.random_state)\n",
    "        ind = np.random.choice(len(X), size=M)\n",
    "        Xk=X[ind]\n",
    "        w0 = -np.sum(Xk*w, axis=1, keepdims=True)\n",
    "        w = np.hstack((w0, w))\n",
    "        self.w = w\n",
    "\n",
    "        Xa = self._Xa_construction(X)\n",
    "        KC = self._Kesler_construction(X, y)\n",
    "\n",
    "        # transform X from d-dim feature to M-dim feature\n",
    "        C = np.tanh(np.dot(Xa, w.T))\n",
    "        Ca = self._Xa_construction(C)\n",
    "\n",
    "        # calculate error weights for ensembled classifier\n",
    "        e = np.dot(np.linalg.pinv(Ca), KC)\n",
    "        self.e = e\n",
    "\n",
    "    def predict(self, query):\n",
    "        labels = self.Keslerlabel\n",
    "        query_a = self._Xa_construction(query)\n",
    "\n",
    "        C = np.tanh(np.dot(query_a, self.w.T))\n",
    "        Ca = self._Xa_construction(C)\n",
    "\n",
    "        y = np.argmax(np.dot(Ca, self.e), axis=1)\n",
    "\n",
    "        pred = np.zeros_like(y)\n",
    "\n",
    "        for k, v in labels.items():\n",
    "            pred[y==k]=v\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of 6 class\n",
    "def confusion_matrix(pred, y):   \n",
    "    conf_mat_6 = np.zeros((6,6))\n",
    "\n",
    "    for i in np.arange(6):\n",
    "        for j in np.arange(6):\n",
    "            conf_mat_6[i][j]=np.sum((y==i)&(pred==j))\n",
    "\n",
    "    return conf_mat_6.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ensemble_linear_classifier(n_estimators=30, random_state=42)\n",
    "clf.fit(P, y_train)\n",
    "\n",
    "# training set accuracy\n",
    "pred_tr = clf.predict(P)\n",
    "conf_mat_tr = confusion_matrix(pred_tr, y_train)\n",
    "\n",
    "#PCA on test data\n",
    "P_test = np.dot((X_test-mean_vec), V.T)\n",
    "\n",
    "# test set accuracy\n",
    "pred_test = clf.predict(P_test)\n",
    "conf_mat_test = confusion_matrix(pred_test, y_test)\n",
    "\n",
    "print (conf_mat_tr, \"\\n\\n\", conf_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Ensemble_linear_classifier(n_estimators=60, random_state=42)\n",
    "clf.fit(P, y_train)\n",
    "\n",
    "# training set accuracy\n",
    "pred_tr = clf.predict(P)\n",
    "conf_mat_tr = confusion_matrix(pred_tr, y_train)\n",
    "\n",
    "#PCA on test datar\n",
    "P_test = np.dot((X_test-mean_vec), V.T)\n",
    "\n",
    "# test set accuracy\n",
    "pred_test = clf.predict(P_test)\n",
    "conf_mat_test = confusion_matrix(pred_test, y_test)\n",
    "\n",
    "print (conf_mat_tr, \"\\n\\n\", conf_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot decision boundary\n",
    "h = 50 # step size in the mesh\n",
    "x_min, x_max = P[:, 0].min()-100, P[:, 0].max() + 100\n",
    "y_min, y_max = P[:, 1].min()-100, P[:, 1].max() + 100\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "q = np.array([xx.ravel(), yy.ravel()]).T\n",
    "pred_mesh = clf.predict(q)\n",
    "zz = pred_mesh.reshape(xx.shape)\n",
    "\n",
    "class_ids = [0,1,2,3,4,5]\n",
    "colors = ['cyan', 'red', 'green', 'orange', 'blue', 'magenta']\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['bottom'].set_color('gray')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "ax.spines['left'].set_color('gray')\n",
    "for i in np.arange(len(class_ids)):\n",
    "    plt.scatter(P[:,0][y_train==class_ids[i]], P[:,1][y_train==class_ids[i]], c=colors[i], s = 10, label = \"class %i\"%class_ids[i], alpha=0.7)\n",
    "ax.legend()\n",
    "plt.contourf(xx, yy, zz, cmap=plt.cm.nipy_spectral, alpha=0.2)\n",
    "ax.legend()\n",
    "#plt.savefig(\"decision_boundary_2PC_ensemble.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'w':clf.w, 'e':clf.e}\n",
    "params['w'].shape, params['e'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Ensemble_2D.npy\", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
